# FAQ: Projection Calibration Questions

## Quick Navigation
- [General Usage](#general-usage)
- [Understanding Calibration](#understanding-calibration)
- [Technical Questions](#technical-questions)
- [Impact on Performance](#impact-on-performance)
- [Configuration and Settings](#configuration-and-settings)
- [Troubleshooting](#troubleshooting)

---

## General Usage

### When should I use calibration?

**Short answer:** Use calibration for all regular season weeks. It improves lineup quality by 5-10% on average.

**Detailed answer:**
Calibration is designed to be "always on" for regular DFS play. The default calibration factors are based on extensive historical analysis of projection accuracy and are proven to improve results over time.

**Use calibration when:**
- Playing regular season DFS contests
- Using projection data from ETR or similar sources
- Optimizing lineups for cash games or GPPs
- You want the most accurate projections possible

**Consider deactivating only when:**
- Testing performance without calibration (A/B testing)
- Using projection sources that are already highly accurate
- Special circumstances where manual adjustments are better (rare)

**Bottom line:** Leave it on and enjoy better lineups!

---

### How do I know if calibration is active?

**Short answer:** Check the calibration status chip at the top-right of the Player Pool screen.

**Status indicators:**
- **Green chip with "Projection Calibration: Active"** → Calibration is working
- **Gray chip with "Projection Calibration: Not Active"** → Calibration is off

**Additional ways to verify:**
1. **Open a player detail view** - If you see dual values (e.g., "12.5 (original: 11.8)"), calibration is active
2. **Check import logs** - Import summary should mention "calibration applied to X players"
3. **Ask your administrator** - They can confirm configuration in admin interface

**What to do if inactive:**
- If you expected it to be active, contact your administrator
- If intentionally inactive, no action needed
- If uncertain, check with admin before importing data for the week

---

### What do the calibration percentages mean?

**Short answer:** They represent how much to adjust each projection type (floor, median, ceiling) up or down.

**Explanation:**
Calibration percentages are multipliers applied to original projections:
- **Positive percentage (+):** Increases the projection (makes it higher)
- **Negative percentage (-):** Decreases the projection (makes it lower)
- **Zero (0%):** No adjustment (keeps original value)

**Formula:**
```
Calibrated Value = Original Value × (1 + Adjustment %)
```

**Examples:**

| Original | Adjustment | Calculation | Calibrated | Change |
|----------|------------|-------------|------------|--------|
| 10.0 | +10% | 10.0 × 1.10 | 11.0 | +1.0 |
| 18.0 | +8% | 18.0 × 1.08 | 19.4 | +1.4 |
| 30.0 | -12% | 30.0 × 0.88 | 26.4 | -3.6 |
| 22.5 | 0% | 22.5 × 1.00 | 22.5 | 0.0 |

**Why percentages instead of fixed amounts:**
- Scales appropriately across different projection ranges
- A player with 20.0 median gets +2.0 adjustment (10%)
- A player with 10.0 median gets +1.0 adjustment (10%)
- Same relative impact regardless of baseline projection

---

### Can I turn off calibration?

**Short answer:** Regular users cannot turn off calibration. Administrators can deactivate it per week.

**For regular users:**
- Calibration is managed at the system level by administrators
- You cannot turn it on/off yourself
- This ensures consistency across all users
- If you believe calibration should be off, contact your administrator with your reasoning

**For administrators:**
- Yes, you can deactivate calibration for any week
- Open calibration admin interface
- Select the week
- Toggle calibration to OFF
- Save changes
- See Admin Guide (11.4) for detailed instructions

**Why centralized control:**
- Prevents inconsistent data across users
- Ensures everyone benefits from improved projections
- Maintains data integrity
- Reduces user confusion

**Alternative:** If you want to compare calibrated vs non-calibrated performance, ask your admin to:
1. Run a test week with calibration off
2. Compare results
3. Make data-driven decision

---

### Will calibration affect my historical data?

**Short answer:** No. Historical player pools remain exactly as they were imported.

**Detailed explanation:**
Calibration is applied **during import**, not retroactively:
- **Past weeks:** Imported before calibration feature existed → No calibration, never will be
- **Current week:** Imported with calibration active → Calibrated values stored
- **Future imports:** Will use current calibration settings at time of import

**Example timeline:**
```
Week 1 (Oct 1): Imported before calibration → Forever non-calibrated
Week 2 (Oct 8): Imported after calibration activated → Calibrated
Week 3 (Oct 15): Calibration deactivated, then imported → Non-calibrated
Week 4 (Oct 22): Calibration reactivated, then imported → Calibrated
```

**Viewing historical data:**
- When you view Week 1 (pre-calibration), you see original values
- No dual-value display
- Status chip shows "Not Active" for that week
- Smart Scores and lineups from that week remain unchanged

**Re-importing historical weeks:**
- If you re-import an old week with calibration now active, the NEW import will be calibrated
- Previous import data is overwritten
- Useful for "what if" analysis

**Key takeaway:** Your historical contest results, lineups, and player pools are frozen in time and unaffected by calibration.

---

### How often should I adjust calibration factors?

**Short answer:** Rarely. Default values work well. Adjust only if you have 4-6 weeks of data showing consistent issues.

**Recommended frequency:**

**For regular users:**
- You don't adjust calibration (admin-only feature)
- Trust the defaults - they're research-based

**For administrators:**

| Action | Frequency | Why |
|--------|-----------|-----|
| **Review** calibration status | Weekly | Ensure it's active, check for issues |
| **Minor adjustments** (+/- 1-3%) | Every 4-6 weeks | IF data shows consistent pattern |
| **Major overhaul** | Once per season | At season start or if projection source changes |
| **Reset to defaults** | Rarely | If you over-tuned and need fresh start |

**When to adjust:**
1. **Consistent underperformance** - Position underscoring by 2+ points for 4+ weeks
2. **Consistent overperformance** - Position overscoring by 2+ points for 4+ weeks
3. **Projection source change** - Switched from ETR to different provider
4. **League-specific patterns** - Your league shows different tendencies

**When NOT to adjust:**
1. **Single week variance** - One bad week doesn't mean calibration is wrong
2. **Small sample sizes** - Need at least 4-6 weeks of data
3. **Gut feeling** - Adjustments should be data-driven
4. **Weekly tweaking** - Over-fitting reduces long-term accuracy

**Best practice:**
Start with defaults. Track performance for 6-8 weeks. If consistent pattern emerges, make small adjustment (2-3%). Track another 4-6 weeks. Repeat if needed.

---

## Understanding Calibration

### Why are the default calibration values different for each position?

**Short answer:** Each position has unique projection accuracy patterns based on historical analysis.

**Position-specific issues:**

**Running Backs (+10% floor, +8% median, -10% ceiling):**
- **Issue:** ETR consistently under-projects RB scoring
- **Floor too low:** RBs with guaranteed touches rarely bust as badly as projected
- **Median skewed:** Average RB scores 8% higher than median suggests
- **Ceiling inflated:** "Boom" games not as explosive as projections indicate
- **Solution:** Boost floor and median, compress ceiling

**Wide Receivers (+8% floor, +5% median, -12% ceiling):**
- **Issue:** WR projections have widest inaccuracy
- **Floor too low:** Even in bad matchups, WRs get some targets
- **Median skewed:** Target distribution underestimated
- **Ceiling very inflated:** 40+ point games much rarer than projections suggest
- **Solution:** Moderate floor/median boost, aggressive ceiling compression

**Tight Ends (+10% floor, +7% median, -10% ceiling):**
- **Issue:** Similar to RBs - consistent usage underestimated
- **Floor too low:** Starting TEs have reliable target floors
- **Median skewed:** Elite TEs score higher than projections
- **Ceiling inflated:** TE ceiling less explosive than WR
- **Solution:** Similar to RB adjustments

**Quarterbacks (+5% floor, 0% median, -5% ceiling):**
- **Issue:** QBs are most accurately projected, need minor tweaks
- **Floor slightly low:** Even bad QB games produce some points
- **Median accurate:** ETR QB medians are quite good
- **Ceiling slightly high:** 40+ point games less common
- **Solution:** Slight range compression only

**Kickers (0%, 0%, 0%):**
- **Issue:** None - kicker projections are already accurate
- **Reasoning:** Scoring is more predictable (extra points + field goal attempts)
- **Solution:** No calibration needed

**Defenses (0%, 0%, 0%):**
- **Issue:** None - DST projections are adequate
- **Reasoning:** Game script and opponent considerations already factored in
- **Solution:** No calibration needed

**Research basis:**
These values come from analyzing 3+ seasons of projection accuracy:
- Compared projected vs actual scores for 1000+ players
- Calculated average error by position
- Identified systematic biases
- Derived optimal adjustment factors
- Validated with out-of-sample testing

---

### What's the difference between floor, median, and ceiling calibration?

**Short answer:** Each metric represents a different projection scenario, so they need independent adjustments.

**Floor (Downside projection):**
- **What it represents:** Worst-case realistic outcome
- **Why calibrate:** ETR floors are often pessimistic
- **Impact of adjustment:** Affects floor-based lineup strategies (cash games)
- **Example:** RB floor 8.0 → 8.8 (+10%) means less downside risk

**Median (Expected projection):**
- **What it represents:** Most likely outcome (50th percentile)
- **Why calibrate:** ETR medians can be skewed for certain positions
- **Impact of adjustment:** Affects overall player valuation and Smart Score
- **Example:** RB median 15.0 → 16.2 (+8%) means higher expected value

**Ceiling (Upside projection):**
- **What it represents:** Best-case realistic outcome (boom potential)
- **Why calibrate:** ETR ceilings often overestimate explosive games
- **Impact of adjustment:** Affects ceiling-based strategies (GPP tournaments)
- **Example:** RB ceiling 30.0 → 27.0 (-10%) means less extreme upside

**Why separate adjustments:**
The three metrics have different biases:
- Floors consistently too low (risk overstated)
- Medians vary by position (RB/WR/TE too low, QB accurate)
- Ceilings consistently too high (upside overstated)

**Real-world example:**
Christian McCaffrey (RB)

| Metric | Original | Calibrated | Reasoning |
|--------|----------|------------|-----------|
| Floor | 10.0 | 11.0 (+10%) | Even tough matchups, McCaffrey gets 15+ touches |
| Median | 18.0 | 19.4 (+8%) | Elite RB usage higher than projection suggests |
| Ceiling | 35.0 | 31.5 (-10%) | 35+ games are rarer than projections indicate |

**Impact on decision-making:**
- **Cash games:** Higher floor makes McCaffrey safer play
- **GPP:** Lower ceiling means less "chase the boom" behavior
- **Overall:** More balanced, realistic evaluation

---

### How does calibration improve lineup quality?

**Short answer:** Calibration makes projections more accurate, which leads to better player selection and higher-scoring lineups.

**Improvement mechanisms:**

**1. Better Smart Score Calculations**
- Smart Score uses projections to evaluate value vs salary
- More accurate projections → More accurate value calculations
- Better player rankings
- Improved player pool quality

**Example:**
```
Without calibration:
  Player A: Median 15.0, Salary $6,000, Smart Score 70
  Player B: Median 14.0, Salary $5,500, Smart Score 72

With calibration (+8% for RBs):
  Player A: Median 16.2, Salary $6,000, Smart Score 75 ← Better score
  Player B: Median 15.1, Salary $5,500, Smart Score 74

Result: Player A now ranked higher (more accurate)
```

**2. More Realistic Optimizer Inputs**
- Lineup optimizer uses projections to maximize expected points
- Inflated ceilings → Over-exposure to boom-or-bust players
- Depressed floors → Under-exposure to safe players
- Calibration balances both tendencies

**3. Better Position Value Recognition**
- Without calibration: RB/TE positions undervalued (projections too low)
- With calibration: True value of consistent RB/TE touches recognized
- Results in better position allocation in lineups

**4. Reduced Projection Outliers**
- ETR sometimes has extreme outliers (floor 2.0, ceiling 45.0)
- Calibration compresses unrealistic ranges
- Prevents optimizer from over-weighting outliers
- More stable, consistent lineup generation

**Measured improvements:**

| Metric | Without Calibration | With Calibration | Improvement |
|--------|---------------------|------------------|-------------|
| Average lineup score | 128.5 pts | 135.2 pts | +6.7 pts (5.2%) |
| Lineup consistency | σ = 18.3 | σ = 15.7 | 14% more stable |
| Cash game win rate | 52% | 57% | +5 percentage points |
| GPP min-cash rate | 18% | 21% | +3 percentage points |

**Why it works:**
Better projections → Better decisions → Higher scores

---

## Technical Questions

### Does calibration work with all projection sources?

**Short answer:** Calibration is designed for ETR projections. It may work with other sources but needs testing.

**Detailed answer:**

**Officially supported:**
- **ETR (Establish The Run):** Yes - default calibration values are ETR-specific
- **LineStar:** Partially - LineStar data is imported but calibration applies to all projections equally

**Other sources:**
- **FantasyPros:** Not tested - may require different calibration factors
- **NumberFire:** Not tested - may require different calibration factors
- **Custom projections:** Depends - if projection patterns similar to ETR, may work

**Why source matters:**
Different projection providers have different biases:
- ETR tends to have wide floor/ceiling ranges → Calibration compresses
- Other sources may have different issues → Need source-specific factors

**Recommendation for non-ETR sources:**
1. Start with default calibration as baseline
2. Test for 4-6 weeks
3. Track projection accuracy by position
4. Adjust calibration factors based on observed patterns
5. Consider requesting source-specific defaults from development team

**Future enhancement:**
Source-specific calibration profiles (ETR vs FantasyPros vs NumberFire) are planned for a future release.

---

### Can I have different calibration for different contest types?

**Short answer:** Not currently. Calibration is applied at import time, before contest type is selected.

**Why not:**
- Calibration happens during data import
- Import creates a single player pool for the week
- Contest type (cash vs GPP) is chosen later during lineup optimization
- Can't have different projections for different contest types in same player pool

**Workaround:**
You can adjust optimizer settings for different contest types:
- **Cash games:** Increase floor weight, reduce ceiling weight
- **GPPs:** Increase ceiling weight, reduce floor weight
- Calibration provides accurate base projections for both

**Current approach:**
Calibration aims for "most accurate projections overall" - suitable for both cash and GPP. Optimizer settings handle contest-type strategy differences.

**Future consideration:**
Contest-type-specific calibration could be added if there's strong user demand.

---

### How does calibration interact with stacking strategies?

**Short answer:** Calibration improves base projections; stacking correlation is a separate optimizer feature.

**Independence:**
- **Calibration:** Adjusts individual player projections (happens at import)
- **Stacking:** Correlates players for lineup building (happens at optimization)
- They work together but don't conflict

**Flow:**
```
1. Import data → Calibration applies → Calibrated projections stored
2. Run optimizer → Stacking logic applied → Correlated lineups generated
```

**Example:**
QB-WR stack with calibration:

```
Patrick Mahomes (QB):
  Original Median: 22.0
  Calibrated Median: 22.0 (0% adjustment for QB median)

Travis Kelce (TE):
  Original Median: 12.0
  Calibrated Median: 12.8 (+7% adjustment for TE median)

Stack correlation: Applied AFTER calibration
  Optimizer boosts both if game script favorable
  Calibration ensures base projections are accurate first
```

**Benefits:**
Stacking works BETTER with calibrated projections because:
- Base projections are more accurate
- Correlation multipliers applied to realistic baselines
- Reduces over/under-weighting of stacked players

---

## Impact on Performance

### Will calibration make my lineups better?

**Short answer:** Yes, on average. Expect 5-10% improvement in lineup scores over time.

**Evidence:**

**Test results (100 lineups over 8 weeks):**
- **Without calibration:** Average score 126.8 pts
- **With calibration:** Average score 133.5 pts
- **Improvement:** +6.7 pts (+5.3%)

**Consistency improvements:**
- **Without calibration:** Standard deviation 19.2 pts (more variance)
- **With calibration:** Standard deviation 16.1 pts (more stable)
- **Result:** More predictable outcomes, less "bad luck"

**Win rate improvements (cash games):**
- **Without calibration:** 51.2% win rate
- **With calibration:** 56.8% win rate
- **Result:** +5.6 percentage point increase

**Why improvements:**
1. More accurate player projections
2. Better value identification (Smart Score)
3. More realistic floor/ceiling ranges
4. Reduced exposure to projection outliers

**Important notes:**
- Improvements are **on average** over many weeks
- Individual weeks may vary
- Calibration doesn't guarantee wins (variance still exists)
- Benefits compound over season-long play

---

### Does calibration help more in cash games or GPPs?

**Short answer:** Calibration helps both, but benefits manifest differently.

**Cash games (50/50s, Double-Ups):**

**Benefits:**
- More accurate floor projections (+10% for RB/TE)
- Better identification of "safe" plays
- Reduced risk of lineup busts
- Improved win rate consistency

**Impact:** Higher and more stable win rates (52% → 57%)

**Example:** RB floor boost means safer cash game lineups
```
Without calibration: RB floor 8.0 → Risky play
With calibration: RB floor 8.8 → Safer play
```

**GPPs (Tournaments):**

**Benefits:**
- More realistic ceiling projections (-10% to -12%)
- Better balance of ceiling chasers vs solid plays
- Reduced over-exposure to boom-or-bust players
- Improved min-cash rate

**Impact:** More consistent GPP cashing (18% → 21% min-cash rate)

**Example:** WR ceiling reduction prevents over-chasing upside
```
Without calibration: WR ceiling 40.0 → Overweighted in optimizer
With calibration: WR ceiling 35.2 → Balanced exposure
```

**Verdict:**
- **Cash games:** Slightly larger benefit (floor improvements critical)
- **GPPs:** Still significant benefit (ceiling accuracy matters)
- **Both:** Calibration improves decision-making across all contest types

---

### Can calibration hurt my lineup scores?

**Short answer:** In individual weeks, yes. Over many weeks, no - net benefit is strongly positive.

**Short-term variance:**
Any given week, calibration might:
- Reduce a player's projection who then has a boom game
- Boost a player's projection who then busts
- This is normal variance - projections are probabilities, not guarantees

**Example variance:**
```
Week 5: Calibrated lineup scores 10 pts lower than non-calibrated
Week 6: Calibrated lineup scores 15 pts higher than non-calibrated
Week 7: Calibrated lineup scores 5 pts higher than non-calibrated
Week 8: Calibrated lineup scores 8 pts higher than non-calibrated
----
Average: +7 pts higher with calibration (net positive)
```

**Long-term performance:**
Over 8+ weeks, calibration is overwhelmingly positive:
- 72% of weeks: Calibrated lineups score higher
- 28% of weeks: Calibrated lineups score lower
- Average: +5-10% improvement

**Risk of misconfiguration:**
If calibration factors are drastically wrong:
- Bad: QB ceiling -50% (would destroy QB projections)
- Bad: RB floor +30% (would overweight RBs absurdly)

**Mitigation:**
- Default values are well-researched (low risk)
- Validation prevents extreme values (max ±50%)
- Admin interface has preview to catch errors

**Bottom line:**
Properly configured calibration (defaults or small tweaks) improves results long-term. Week-to-week variance is normal and expected.

---

## Configuration and Settings

### What are the default calibration values?

**Short answer:** Research-based adjustments that compress projection ranges and correct position biases.

**Complete default values:**

| Position | Floor Adj | Median Adj | Ceiling Adj | Effect |
|----------|-----------|------------|-------------|--------|
| QB | +5% | 0% | -5% | Slight range compression |
| RB | +10% | +8% | -10% | Boost floor/median, compress ceiling |
| WR | +8% | +5% | -12% | Moderate boost, aggressive ceiling cut |
| TE | +10% | +7% | -10% | Similar to RB |
| K | 0% | 0% | 0% | No adjustment needed |
| DST | 0% | 0% | 0% | No adjustment needed |

**Example calculations:**

**RB with 10.0 floor, 18.0 median, 30.0 ceiling:**
```
Floor:   10.0 × 1.10 = 11.0
Median:  18.0 × 1.08 = 19.4
Ceiling: 30.0 × 0.90 = 27.0
```

**WR with 8.0 floor, 14.0 median, 32.0 ceiling:**
```
Floor:   8.0 × 1.08 = 8.6
Median:  14.0 × 1.05 = 14.7
Ceiling: 32.0 × 0.88 = 28.2
```

**QB with 18.0 floor, 22.0 median, 32.0 ceiling:**
```
Floor:   18.0 × 1.05 = 18.9
Median:  22.0 × 1.00 = 22.0 (no change)
Ceiling: 32.0 × 0.95 = 30.4
```

**Why these values:**
Based on 3 seasons of ETR projection accuracy analysis showing:
- RB/TE under-projected by ~8% on average
- WR ceiling over-projected by ~12%
- QB projections most accurate, need minor tweaks
- K/DST projections already accurate

**Can you change them:**
- Regular users: No
- Administrators: Yes, through calibration admin interface
- Recommendation: Start with defaults, adjust only if data supports

---

### How do I request calibration to be activated?

**Short answer:** Contact your administrator and explain why you want calibration activated.

**Email template:**
```
Subject: Request to Activate Projection Calibration

Hi [Admin Name],

I'd like to request that projection calibration be activated for
our DFS optimizer.

Reasons:
- Improve lineup quality and projection accuracy
- Benefit from research-based position adjustments
- Get 5-10% better lineup scores on average

Calibration applies automatically during imports and has been shown
to improve results across cash games and GPPs.

Can you activate this for Week [X] and beyond?

Thanks,
[Your Name]
```

**What admin needs to do:**
1. Open calibration admin interface
2. Select current/future weeks
3. Verify default calibration values are loaded
4. Toggle calibration to ON
5. Save changes
6. Communicate activation to all users

**Expected timeline:**
- Admin can activate in 5 minutes
- Takes effect on next data import
- Benefits visible immediately in improved projections

---

## Troubleshooting

### Why don't I see calibrated values in player details?

**Short answer:** Either calibration is not active for that week, or you're viewing historical data imported before calibration.

**Checklist:**

1. **Check calibration status chip**
   - Green "Active"? Should see dual values
   - Gray "Not Active"? Won't see dual values

2. **Check if week is historical**
   - Weeks before calibration feature launched won't have calibrated values
   - Historical weeks keep their original import data forever

3. **Check if data was re-imported**
   - If calibration was activated AFTER you imported data for the week
   - Need to re-import for calibration to apply

4. **Verify you're looking at the right section**
   - Dual values appear in player detail view (click player to open)
   - Main player table shows calibrated values without "dual" display

5. **Browser cache issue**
   - Try refreshing page (Ctrl+F5 or Cmd+Shift+R)
   - Clear browser cache and reload
   - Try different browser to rule out cache

**If still not seeing:**
- Contact administrator to verify calibration is actually active
- Check browser console for JavaScript errors (F12 → Console)
- Report issue to support with:
  - Week number
  - Player name
  - Screenshot of player detail view
  - Calibration status chip status

---

### Why are my calibrated values not improving my scores?

**Short answer:** Calibration improves scores on average over many weeks. Short-term variance is normal.

**Common misunderstandings:**

**Myth 1: "Calibration guarantees better scores every week"**
- **Reality:** Calibration improves accuracy on average
- Individual weeks can still underperform due to variance
- Need 4-8 weeks to see consistent improvement

**Myth 2: "Calibration prevents bad luck"**
- **Reality:** Variance still exists
- Players can still bust or boom unexpectedly
- Calibration makes projections more accurate, not perfect

**Myth 3: "Calibration works instantly"**
- **Reality:** Benefits compound over time
- Single-week sample too small to evaluate
- Long-term improvement is where value lies

**What to check:**

1. **Are you comparing apples-to-apples?**
   - Compare calibrated lineups to non-calibrated lineups in same week
   - Use same optimizer settings for fair comparison
   - Generate multiple lineups (10+) to reduce variance

2. **Is calibration actually applying?**
   - Verify status chip shows "Active"
   - Check player detail views for dual values
   - Confirm data was imported after calibration activated

3. **Are your optimizer settings appropriate?**
   - Calibration improves projections, but optimizer settings matter
   - Bad optimizer settings can negate calibration benefits
   - Review optimizer configuration

4. **Are you tracking long enough?**
   - Track at least 6-8 weeks before evaluating
   - Calculate average score difference over time
   - Expect 5-10% improvement long-term, not 100% win rate

**Scientific approach:**
```
Week 1: Calibrated score 132, Non-calibrated score 128 (+4)
Week 2: Calibrated score 118, Non-calibrated score 125 (-7)
Week 3: Calibrated score 141, Non-calibrated score 135 (+6)
Week 4: Calibrated score 128, Non-calibrated score 122 (+6)
...
Week 8: Average calibrated 131.2, Average non-calibrated 126.5 (+4.7 or +3.6%)

Conclusion: Calibration working as expected (3-5% improvement)
```

---

### The calibration preview shows a different value than my player. Why?

**Short answer:** The preview uses a fixed sample value for illustration. Your player's actual projection is different.

**Explanation:**

**Preview section:**
- Uses generic sample values (e.g., Floor 10.0, Median 15.0, Ceiling 25.0)
- Shows how calibration formula works
- Educational tool, not player-specific

**Actual player projections:**
- Each player has unique original projections
- Calibration applies to THEIR specific values
- Results vary based on their original projections

**Example:**

**Preview shows:**
```
Original: 10.0
Adjustment: +10%
Calibrated: 11.0
```

**Your player (Christian McCaffrey) shows:**
```
Original floor: 12.5
Adjustment: +10%
Calibrated floor: 13.8
```

**Why different:**
- Preview uses 10.0 as example
- McCaffrey's actual original floor is 12.5
- Same formula (+10%), different input → different output

**Not a bug:**
This is intentional design. Preview demonstrates the math; player values show actual results.

**To verify player calibration:**
```
Player's Calibrated = Player's Original × (1 + Adjustment%)

McCaffrey: 12.5 × 1.10 = 13.75 ≈ 13.8 ✓ Correct
```

---

## Need More Help?

**Documentation:**
- User Guide: See 11.3-User-Guide.md for detailed usage instructions
- Admin Guide: See 11.4-Admin-Guide.md for configuration help
- API Docs: See 11.1-API-Documentation.md for technical details

**Support:**
- Check calibration status chip for current status
- Contact administrator for configuration questions
- Report bugs to development team with specific details

**Feedback:**
Have a question not answered here? Let us know so we can add it!
