# Issue Tracking and Resolution Procedures
# Smart Score Engine Enhancement - Projection Calibration System

**Document Version:** 1.0
**Date:** 2025-11-01
**Task:** 13.4 - Address Production Issues
**Status:** Development Environment - Issue Management Procedures

---

## Overview

This document defines procedures for tracking, prioritizing, and resolving production issues related to the Projection Calibration System. It covers:

1. **Bug Discovery and Reporting**
2. **User-Reported Issue Management**
3. **Default Calibration Value Adjustments**
4. **Error Message Improvements**
5. **UI Refinement Based on Usage**

---

## 1. Bug Discovery and Resolution Process

### 1.1 Issue Severity Classification

**CRITICAL (P0) - Immediate Response Required**
- System-wide calibration failure
- Data corruption or loss
- Import process completely broken
- Security vulnerability
- User data exposure

**Response Time:** < 1 hour
**Escalation:** Page on-call engineer immediately
**Resolution Target:** < 4 hours

**HIGH (P1) - Urgent**
- Calibration not applying to subset of players
- Smart Score calculation errors with calibrated data
- Lineup optimizer generating invalid lineups
- Admin interface not saving changes
- API endpoint returning 500 errors

**Response Time:** < 4 hours
**Escalation:** Alert engineering team
**Resolution Target:** < 24 hours

**MEDIUM (P2) - Important**
- Calibration status chip not updating
- Dual-value display formatting issues
- Performance degradation (> 5% overhead)
- Missing error messages
- Non-critical validation errors

**Response Time:** < 24 hours
**Escalation:** Create ticket, assign to sprint
**Resolution Target:** < 1 week

**LOW (P3) - Nice to Have**
- UI polish improvements
- Error message wording
- Minor UX enhancements
- Documentation updates
- Feature requests

**Response Time:** Next sprint planning
**Escalation:** Backlog item
**Resolution Target:** 2-4 weeks

---

### 1.2 Bug Discovery Channels

**1. Automated Monitoring Alerts**
- Error rate threshold exceeded
- Performance degradation detected
- Data integrity check failures
- API endpoint failures

**Action:** Automated ticket creation in issue tracker

**2. User Reports**
- Support tickets
- In-app feedback
- Email reports
- Community forum posts

**Action:** Support team creates ticket, tags with "user-reported"

**3. Internal QA Testing**
- Regression testing
- Manual QA cycles
- Edge case exploration

**Action:** QA team creates ticket with reproduction steps

**4. Developer Discovery**
- Code review findings
- Pair programming sessions
- Production debugging

**Action:** Developer creates ticket with context

---

### 1.3 Issue Tracking Template

**Issue Title Format:**
```
[CALIBRATION] [SEVERITY] Brief description
Example: [CALIBRATION] [P1] Calibration not applied to RB position
```

**Issue Description Template:**
```markdown
## Summary
Brief description of the issue (1-2 sentences)

## Severity
[ ] P0 - Critical
[ ] P1 - High
[ ] P2 - Medium
[ ] P3 - Low

## Environment
- Environment: Production / Staging / Development
- Version: v1.0.2
- Browser (if frontend): Chrome 120
- User Impact: How many users affected?

## Steps to Reproduce
1. Navigate to Player Pool screen
2. Select week 19
3. Import DraftKings data
4. Observe calibration not applied to RB position

## Expected Behavior
Calibration should apply to all 6 positions (QB, RB, WR, TE, K, DST)

## Actual Behavior
Calibration applied to QB, WR, TE, K, DST but not RB

## Screenshots/Logs
[Attach relevant screenshots, log excerpts, or error messages]

## Error Messages
```
Error: Calibration factor not found for position RB
```

## Database State
- Week ID: 19
- Calibration exists for RB: Yes/No
- Calibration is_active for RB: Yes/No

## Additional Context
- Related to recent code change? (commit hash)
- Similar issues in the past?
- Workaround available?

## Proposed Solution
[Optional: Developer's initial assessment]
```

---

### 1.4 Bug Fix Workflow

**Step 1: Triage (< 30 minutes)**
- Verify issue is reproducible
- Confirm severity classification
- Assign to appropriate engineer
- Notify stakeholders if P0/P1

**Step 2: Investigation (timeboxed)**
- Review error logs
- Check database state
- Reproduce in local/staging environment
- Identify root cause

**Investigation Time Limits:**
- P0: 1 hour before escalation
- P1: 4 hours before escalation
- P2: 1 day before reassignment
- P3: As needed

**Step 3: Fix Development**
- Create fix branch: `fix/calibration-issue-{issue-number}`
- Write failing test that reproduces bug
- Implement fix
- Verify test passes
- Add regression test if needed

**Step 4: Testing**
- Unit tests pass
- Integration tests pass
- Manual QA in staging
- Performance validation (no regression)

**Step 5: Deployment**
- Code review (expedited for P0/P1)
- Deploy to staging
- Smoke test in staging
- Deploy to production
- Monitor for 1 hour after deployment

**Step 6: Verification**
- Confirm fix resolves issue
- No new errors introduced
- Performance metrics stable
- User notified if applicable

**Step 7: Post-Mortem (P0/P1 only)**
- Document root cause
- Identify prevention measures
- Update tests/monitoring
- Share learnings with team

---

### 1.5 Common Bug Categories and Solutions

#### Bug Category 1: Calibration Not Applied

**Symptoms:**
- `calibration_applied = false` when should be true
- Original and calibrated values are identical
- No calibration factors in database

**Diagnostic Queries:**
```sql
-- Check if calibration exists for week
SELECT * FROM projection_calibration WHERE week_id = :week_id;

-- Check if calibration is active
SELECT * FROM projection_calibration WHERE week_id = :week_id AND is_active = true;

-- Check affected players
SELECT position, COUNT(*) as count, bool_and(calibration_applied) as all_calibrated
FROM player_pools
WHERE week_id = :week_id
GROUP BY position;
```

**Common Causes:**
1. Calibration inactive for week (`is_active = false`)
2. Missing calibration for specific position
3. Import ran before calibration was created
4. Database transaction rollback

**Solutions:**
1. Activate calibration: `UPDATE projection_calibration SET is_active = true WHERE week_id = :week_id`
2. Create missing calibration: Use admin interface or API
3. Re-import data: Trigger fresh import with active calibration
4. Check logs for transaction errors

---

#### Bug Category 2: Incorrect Calibrated Values

**Symptoms:**
- Calibrated value doesn't match formula
- Negative calibrated values
- Extreme values (> 100 or < 0)

**Diagnostic Queries:**
```sql
-- Find calibrated values that don't match formula
SELECT
    pp.player_name,
    pp.position,
    pp.projection_median_original,
    pp.projection_median_calibrated,
    pc.median_adjustment_percent,
    ROUND(pp.projection_median_original * (1 + pc.median_adjustment_percent / 100.0), 2) as expected_calibrated,
    ABS(pp.projection_median_calibrated - ROUND(pp.projection_median_original * (1 + pc.median_adjustment_percent / 100.0), 2)) as difference
FROM player_pools pp
JOIN projection_calibration pc ON pp.week_id = pc.week_id AND pp.position = pc.position
WHERE pp.calibration_applied = true
  AND ABS(pp.projection_median_calibrated - ROUND(pp.projection_median_original * (1 + pc.median_adjustment_percent / 100.0), 2)) > 0.1
LIMIT 20;
```

**Common Causes:**
1. Wrong calibration factor applied (position mismatch)
2. Calculation rounding error
3. Stale cached calibration factors
4. Database update race condition

**Solutions:**
1. Verify position matching logic in `apply_calibration()`
2. Check rounding precision (should be 2 decimal places)
3. Clear calibration cache and re-import
4. Add database constraint: `CHECK (projection_median_calibrated >= 0)`

---

#### Bug Category 3: Admin Interface Not Saving

**Symptoms:**
- Save button clicked but changes not persisted
- UI shows success but database unchanged
- Changes revert after page refresh

**Diagnostic Steps:**
1. Check browser console for JavaScript errors
2. Check network tab for failed API requests
3. Check backend logs for validation errors
4. Query database directly to confirm state

**Diagnostic Queries:**
```sql
-- Check recent calibration updates
SELECT * FROM projection_calibration
WHERE updated_at >= NOW() - INTERVAL '1 hour'
ORDER BY updated_at DESC;

-- Check if week exists
SELECT * FROM weeks WHERE id = :week_id;
```

**Common Causes:**
1. Frontend validation preventing submission
2. Backend validation failing (percentage out of range)
3. Week not found (404 error)
4. Database connection timeout
5. Cache not invalidated after update

**Solutions:**
1. Fix frontend validation logic
2. Return clear error messages from API
3. Verify week exists before saving
4. Increase database connection timeout
5. Call cache invalidation after successful update

---

#### Bug Category 4: Performance Degradation

**Symptoms:**
- Import time > 5% overhead
- Slow API responses (> 200ms)
- Database query timeouts
- High CPU/memory usage

**Diagnostic Queries:**
```sql
-- Find slow queries
SELECT * FROM calibration_query_performance WHERE performance_status = 'CRITICAL';

-- Check index usage
SELECT * FROM pg_stat_user_indexes WHERE tablename = 'player_pools' AND idx_scan < 100;

-- Check table bloat
SELECT pg_size_pretty(pg_total_relation_size('player_pools'));
```

**Common Causes:**
1. Missing database indexes
2. Inefficient COALESCE queries
3. Uncached calibration factor lookups
4. Large result sets without pagination
5. Database needs VACUUM/ANALYZE

**Solutions:**
1. Create missing indexes (see 13.3-PERFORMANCE-OPTIMIZATION-PROCEDURES.md)
2. Optimize queries with EXPLAIN ANALYZE
3. Implement aggressive caching
4. Add pagination to large queries
5. Run `VACUUM ANALYZE player_pools;`

---

## 2. User-Reported Issue Management

### 2.1 Support Ticket Workflow

**Ticket Intake:**
1. User submits issue via support form, email, or in-app feedback
2. Support team logs ticket in ticketing system (e.g., Zendesk, Jira Service Desk)
3. Support team tags with `calibration` label
4. Initial response sent to user (< 4 hours)

**Ticket Categories:**
- **Bug Report:** Something broken or not working as expected
- **Feature Request:** Enhancement or new functionality
- **How-To Question:** User needs guidance
- **Confusion/UX Issue:** User doesn't understand feature

**Ticket Template:**
```markdown
**User:** John Doe (user@example.com)
**Date Reported:** 2025-11-05 14:30 UTC
**Category:** Bug Report
**Component:** Calibration - Dual-Value Display

**User Description:**
"I can't see the original projection values in the player detail view. It only shows one number."

**Support Team Notes:**
- User on Chrome 120, macOS
- Week 19, calibration is active
- Screenshot attached showing single value display

**Reproduction:**
- Confirmed in production
- Only happens when calibration_applied = false
- Expected: Show single value when not calibrated (working as designed)

**Resolution:**
- User education issue, not a bug
- Added tooltip to explain when dual-value appears
- Updated FAQ to clarify this behavior

**Status:** Resolved - User Educated
```

---

### 2.2 Common User Issues and Responses

#### Issue 1: "Calibration is not active, why?"

**User Question:**
> "I see 'Projection Calibration: Not Active' on my player pool. How do I turn it on?"

**Support Response:**
```
Hi [User],

Projection calibration is currently not active for this week because:
- No calibration factors have been set up for this week yet, OR
- Calibration was intentionally disabled for this week

To activate calibration:
1. Click the "Projection Calibration: Not Active" chip at the top right
2. This opens the Calibration Admin interface
3. Review the calibration factors (or reset to defaults)
4. Ensure the "Active" toggle is ON
5. Click "Save"
6. Re-import your player data for calibration to apply

Please note: Calibration only affects ETR projections, not DraftKings salary-based projections.

Let me know if you need further assistance!
```

**Follow-up Actions:**
- Check if defaults were properly seeded (Task 12.3)
- Consider auto-activating calibration for new weeks
- Improve onboarding to explain calibration setup

---

#### Issue 2: "Why are my projections different?"

**User Question:**
> "My player projections changed after I re-imported. Did something break?"

**Support Response:**
```
Hi [User],

Your projections changed because Projection Calibration is now active for this week. This is a new feature that adjusts ETR projection values based on historical accuracy data to improve lineup quality.

You can see both values:
1. Click on any player in the player pool to open the detail view
2. You'll see both the original and calibrated values:
   - Floor: 12.5 (original: 11.8)
   - Median: 18.3 (original: 17.2)
   - Ceiling: 28.1 (original: 30.5)

The calibrated values are used in your Smart Score calculations and lineup generation.

If you prefer to use original projections:
1. Click the calibration status chip
2. Toggle "Active" to OFF
3. Save and re-import

Studies show calibrated lineups score 5-10% higher on average!

Let me know if you have questions.
```

**Follow-up Actions:**
- Track how many users ask this question
- If > 10% of users, improve in-app messaging
- Consider adding "What's New" notification on first login

---

#### Issue 3: "Admin interface is confusing"

**User Question:**
> "I don't understand what the percentage adjustments mean. What's a good value?"

**Support Response:**
```
Hi [User],

Great question! The calibration percentages adjust your projection values:

**Floor Adjustment:** Adjusts the low-end projection
- Example: -10% makes floors less conservative (higher)
- Example: +10% makes floors more conservative (lower)

**Median Adjustment:** Adjusts the expected projection
- Example: +5% increases expected value by 5%
- Example: -5% decreases expected value by 5%

**Ceiling Adjustment:** Adjusts the high-end projection
- Example: -15% reduces ceiling (more realistic)
- Example: +10% increases ceiling (more upside)

**Default Values (Recommended):**
- QB: Floor +5%, Median 0%, Ceiling -5%
- RB: Floor +10%, Median +8%, Ceiling -10%
- WR: Floor +8%, Median +5%, Ceiling -12%
- TE: Floor +10%, Median +7%, Ceiling -10%
- K/DST: 0% (no adjustment)

These defaults are based on historical ETR projection accuracy analysis.

**Tip:** Use the "Reset to Defaults" button to restore these values anytime.

Let me know if you'd like help fine-tuning for your strategy!
```

**Follow-up Actions:**
- Add in-app tooltips explaining percentages
- Include visual preview showing effect on sample player
- Link to user guide documentation

---

### 2.3 User Feedback Aggregation

**Monthly User Feedback Report:**
```markdown
## Calibration Feature Feedback - November 2025

### Tickets Summary
- Total tickets: 45
- Bug reports: 12 (27%)
- Feature requests: 8 (18%)
- How-to questions: 20 (44%)
- UX confusion: 5 (11%)

### Top Issues
1. "How to activate calibration" (15 tickets) - RESOLVED: Improved onboarding
2. "Projections changed unexpectedly" (10 tickets) - RESOLVED: Added notification
3. "Admin percentages confusing" (8 tickets) - IN PROGRESS: Adding tooltips
4. "Can't see dual values" (7 tickets) - RESOLVED: User education
5. "Performance slow after import" (5 tickets) - IN PROGRESS: Performance optimization

### Feature Requests
1. "Copy calibration to multiple weeks" (6 requests) - PRIORITIZED for Phase 2
2. "Historical accuracy tracking" (4 requests) - Deferred feature
3. "Position-specific defaults per league" (3 requests) - Backlog
4. "Undo calibration changes" (2 requests) - Low priority

### Sentiment Analysis
- Positive: 65% (users seeing lineup improvement)
- Neutral: 25% (confused but willing to learn)
- Negative: 10% (frustrated with complexity)

### Action Items
1. Create video tutorial on calibration setup
2. Add in-app tooltips for percentage inputs
3. Improve error messages for failed imports
4. Consider simplified "beginner mode" with preset options
```

---

## 3. Default Calibration Value Adjustments

### 3.1 When to Adjust Defaults

**Triggers for Review:**
- RMSE improvement < 5% (target: 8-12%)
- Lineup quality improvement < 3% (target: 5-10%)
- User complaints about projections being "off"
- Significant meta changes in NFL (rule changes, scoring)

**Review Frequency:**
- Monthly: Check RMSE and lineup performance metrics
- Quarterly: Comprehensive review and potential adjustment
- Yearly: Full recalibration based on full season data

---

### 3.2 Data-Driven Adjustment Process

**Step 1: Collect Performance Data**
```sql
-- Calculate RMSE by position for current defaults
WITH projection_accuracy AS (
    SELECT
        pp.position,
        pp.projection_median_original,
        pp.projection_median_calibrated,
        pas.actual_score,
        POWER(pp.projection_median_original - pas.actual_score, 2) as original_squared_error,
        POWER(pp.projection_median_calibrated - pas.actual_score, 2) as calibrated_squared_error
    FROM player_pools pp
    JOIN player_actual_scores pas ON pp.id = pas.player_pool_id
    WHERE pp.calibration_applied = true
      AND pas.actual_score IS NOT NULL
      AND pp.week_id IN (SELECT id FROM weeks WHERE week_number >= (SELECT MAX(week_number) - 8 FROM weeks))
)
SELECT
    position,
    COUNT(*) as sample_size,
    ROUND(SQRT(AVG(original_squared_error))::numeric, 2) as original_rmse,
    ROUND(SQRT(AVG(calibrated_squared_error))::numeric, 2) as calibrated_rmse,
    ROUND(((SQRT(AVG(original_squared_error)) - SQRT(AVG(calibrated_squared_error))) / SQRT(AVG(original_squared_error)) * 100)::numeric, 2) as improvement_percent
FROM projection_accuracy
GROUP BY position
ORDER BY position;
```

**Step 2: Identify Underperforming Positions**
```
Example Output:
Position | Sample Size | Original RMSE | Calibrated RMSE | Improvement %
---------|-------------|---------------|-----------------|---------------
QB       | 120         | 5.2           | 4.8             | 7.7%  ✓ GOOD
RB       | 180         | 6.8           | 6.5             | 4.4%  ⚠ BELOW TARGET
WR       | 240         | 7.1           | 6.4             | 9.9%  ✓ GOOD
TE       | 95          | 5.9           | 5.7             | 3.4%  ⚠ BELOW TARGET
K        | 80          | 3.2           | 3.2             | 0.0%  ℹ NO CALIBRATION
DST      | 80          | 4.5           | 4.5             | 0.0%  ℹ NO CALIBRATION
```

**Step 3: Analyze Bias Direction**
```sql
-- Check if projections are consistently over or under actual
SELECT
    position,
    AVG(projection_median_calibrated - actual_score) as avg_bias,
    CASE
        WHEN AVG(projection_median_calibrated - actual_score) > 1.0 THEN 'Over-projecting (reduce median%)'
        WHEN AVG(projection_median_calibrated - actual_score) < -1.0 THEN 'Under-projecting (increase median%)'
        ELSE 'Unbiased'
    END as recommendation
FROM player_pools pp
JOIN player_actual_scores pas ON pp.id = pas.player_pool_id
WHERE pp.calibration_applied = true
GROUP BY position;
```

**Step 4: Propose Adjustments**

**RB Position (Currently: Floor +10%, Median +8%, Ceiling -10%)**
- RMSE improvement: 4.4% (target: 8-12%)
- Avg bias: -1.5 points (under-projecting)
- **Proposed change:** Floor +12%, Median +10%, Ceiling -8%
- **Rationale:** Increase median more aggressively to reduce under-projection bias

**TE Position (Currently: Floor +10%, Median +7%, Ceiling -10%)**
- RMSE improvement: 3.4% (target: 8-12%)
- Avg bias: -0.8 points (slight under-projection)
- **Proposed change:** Floor +12%, Median +9%, Ceiling -12%
- **Rationale:** Increase median and compress range more

**Step 5: A/B Test (Optional)**
- Deploy new defaults to 50% of users
- Monitor for 2-3 weeks
- Compare RMSE and lineup performance
- Roll out to 100% if successful

**Step 6: Deploy Updated Defaults**
```sql
-- Update default calibration values
UPDATE projection_calibration
SET
    floor_adjustment_percent = 12.0,
    median_adjustment_percent = 10.0,
    ceiling_adjustment_percent = -8.0,
    updated_at = CURRENT_TIMESTAMP
WHERE position = 'RB'
  AND week_id >= (SELECT id FROM weeks WHERE is_active = true);

-- Log the change
INSERT INTO calibration_change_log (position, old_median, new_median, reason, changed_by, changed_at)
VALUES ('RB', 8.0, 10.0, 'RMSE improvement below target, under-projection bias detected', 'admin', CURRENT_TIMESTAMP);
```

**Step 7: Communicate Changes**
- Email to users explaining improvement
- In-app notification showing new defaults
- Blog post explaining data-driven approach
- Update FAQ and documentation

---

### 3.3 Calibration Value Change Log

**Create Audit Table:**
```sql
CREATE TABLE calibration_change_log (
    id SERIAL PRIMARY KEY,
    position VARCHAR(10),
    change_type VARCHAR(50),  -- 'floor', 'median', 'ceiling', 'all'
    old_value DECIMAL(5,2),
    new_value DECIMAL(5,2),
    reason TEXT,
    data_support TEXT,  -- Link to analysis or metrics
    changed_by VARCHAR(100),
    changed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

**Track All Changes:**
```sql
INSERT INTO calibration_change_log (position, change_type, old_value, new_value, reason, changed_by)
VALUES ('RB', 'median', 8.0, 10.0, 'RMSE improvement below 5%, under-projection bias', 'data_team');
```

**Review History:**
```sql
SELECT * FROM calibration_change_log ORDER BY changed_at DESC LIMIT 20;
```

---

## 4. Error Message Improvements

### 4.1 Current Error Messages Review

**Error Category: Validation Errors**

**Current:**
```
"Error: Invalid adjustment percent"
```

**Improved:**
```
"Calibration adjustment must be between -50% and +50%. You entered: -75%. Please adjust and try again."
```

---

**Current:**
```
"Error: Invalid position"
```

**Improved:**
```
"Position 'DE' is not supported for calibration. Valid positions are: QB, RB, WR, TE, K, DST."
```

---

**Error Category: Import Errors**

**Current:**
```
"Calibration failed"
```

**Improved:**
```
"Calibration could not be applied to 45 players due to missing calibration factors for position 'RB' in week 19. Import completed with original projections. To apply calibration, set up calibration factors and re-import."
```

---

**Error Category: Database Errors**

**Current:**
```
"Internal server error"
```

**Improved:**
```
"Unable to save calibration changes due to a database connection issue. Please try again. If the problem persists, contact support (Error ID: CAL-500-2025110512345)."
```

---

### 4.2 Error Message Improvement Checklist

For each error message, ensure:
- [ ] Explains WHAT went wrong
- [ ] Explains WHY it went wrong (if known)
- [ ] Provides HOW to fix it (actionable next steps)
- [ ] Uses plain language (no technical jargon)
- [ ] Includes specific values (what was expected vs what was received)
- [ ] Provides error ID for support escalation (if server error)
- [ ] Links to relevant documentation (if applicable)

**Example Implementation:**
```python
# In calibration_router.py
from fastapi import HTTPException

@router.post("/{week_id}")
def update_calibration(week_id: int, calibration: CalibrationCreate, db: Session = Depends(get_db)):
    # Validate adjustment percentages
    for field, value in [
        ('floor_adjustment_percent', calibration.floor_adjustment_percent),
        ('median_adjustment_percent', calibration.median_adjustment_percent),
        ('ceiling_adjustment_percent', calibration.ceiling_adjustment_percent)
    ]:
        if value < -50 or value > 50:
            raise HTTPException(
                status_code=400,
                detail={
                    "error": "validation_error",
                    "field": field,
                    "value": value,
                    "message": f"{field.replace('_', ' ').title()} must be between -50% and +50%. You entered: {value}%. Please adjust to a value within the allowed range.",
                    "allowed_range": {"min": -50, "max": 50},
                    "help_url": "https://docs.example.com/calibration/adjustment-percentages"
                }
            )

    # Validate position
    valid_positions = ['QB', 'RB', 'WR', 'TE', 'K', 'DST']
    if calibration.position not in valid_positions:
        raise HTTPException(
            status_code=400,
            detail={
                "error": "invalid_position",
                "value": calibration.position,
                "message": f"Position '{calibration.position}' is not supported for calibration. Valid positions are: {', '.join(valid_positions)}.",
                "valid_positions": valid_positions,
                "help_url": "https://docs.example.com/calibration/supported-positions"
            }
        )

    # ... rest of logic ...
```

---

## 5. UI Refinement Based on Usage Patterns

### 5.1 Usage Analytics Review

**Monthly Analytics Report:**
```javascript
// Sample analytics data
const usageMetrics = {
  calibrationStatusChipClicks: 1250,
  calibrationAdminOpens: 450,
  calibrationFactorUpdates: 89,
  resetToDefaultsClicks: 23,
  playerDetailViewsWithDualValues: 8500,
  avgTimeInCalibrationAdmin: "2m 45s",
  calibrationAdminAbandonmentRate: 0.15  // 15% of users open but don't save
};
```

**Insights:**
1. **High chip click rate** but low admin opens: Users curious but intimidated?
2. **High abandonment rate (15%)**: Admin interface may be confusing
3. **Low reset clicks**: Defaults seem reasonable
4. **High dual-value views**: Feature is being used and noticed

---

### 5.2 UI Refinement Proposals

#### Refinement 1: Simplify Calibration Admin for Beginners

**Current:** All 6 positions × 3 fields = 18 input fields
**Problem:** Overwhelming for new users

**Proposal:**
Add "Simple Mode" toggle:
- **Simple Mode:** Preset options (Conservative, Balanced, Aggressive)
- **Advanced Mode:** Full granular control (current interface)

```tsx
// CalibrationAdmin.tsx
const [mode, setMode] = useState<'simple' | 'advanced'>('simple');

const simplePresets = {
  conservative: { /* -5% floor, 0% median, +5% ceiling */ },
  balanced: { /* 0% all */ },
  aggressive: { /* +10% floor, +5% median, -15% ceiling */ }
};

return (
  <>
    <Toggle label="Mode" value={mode} onChange={setMode} options={['simple', 'advanced']} />

    {mode === 'simple' ? (
      <SimplePresetSelector presets={simplePresets} onSelect={applyPreset} />
    ) : (
      <AdvancedCalibrationInputs positions={positions} factors={factors} onChange={updateFactors} />
    )}
  </>
);
```

**Expected Impact:**
- Reduce abandonment rate from 15% to < 10%
- Increase successful updates by 20%
- Maintain advanced user satisfaction

---

#### Refinement 2: Add Visual Preview with Sample Player

**Current:** Numeric inputs only
**Problem:** Users don't see immediate impact

**Proposal:**
Add live preview panel showing effect on a sample player:

```tsx
// CalibrationPreview.tsx
const CalibrationPreview: React.FC<{ position: string, factors: CalibrationFactors }> = ({ position, factors }) => {
  const samplePlayer = {
    name: "Sample RB",
    floor: 8.5,
    median: 14.2,
    ceiling: 25.3
  };

  const calibrated = {
    floor: samplePlayer.floor * (1 + factors.floor / 100),
    median: samplePlayer.median * (1 + factors.median / 100),
    ceiling: samplePlayer.ceiling * (1 + factors.ceiling / 100)
  };

  return (
    <div className="preview-panel">
      <h4>Preview Effect on Sample {position}</h4>
      <div className="projection-comparison">
        <div className="original">
          <span>Original</span>
          <div>Floor: {samplePlayer.floor.toFixed(1)}</div>
          <div>Median: {samplePlayer.median.toFixed(1)}</div>
          <div>Ceiling: {samplePlayer.ceiling.toFixed(1)}</div>
        </div>
        <div className="arrow">→</div>
        <div className="calibrated">
          <span>Calibrated</span>
          <div>Floor: {calibrated.floor.toFixed(1)} ({factors.floor > 0 ? '+' : ''}{factors.floor}%)</div>
          <div>Median: {calibrated.median.toFixed(1)} ({factors.median > 0 ? '+' : ''}{factors.median}%)</div>
          <div>Ceiling: {calibrated.ceiling.toFixed(1)} ({factors.ceiling > 0 ? '+' : ''}{factors.ceiling}%)</div>
        </div>
      </div>
    </div>
  );
};
```

**Expected Impact:**
- Increase user understanding by 30%
- Reduce support tickets about "what do percentages mean" by 50%
- Improve user confidence in adjustments

---

#### Refinement 3: Enhanced Status Chip with More Info

**Current:** "Projection Calibration: Active" or "Not Active"
**Problem:** Doesn't show coverage (partial vs full calibration)

**Proposal:**
Enhanced chip showing position coverage:

```tsx
// CalibrationStatusChip.tsx
const EnhancedStatusChip: React.FC<{ weekId: number }> = ({ weekId }) => {
  const { data: status } = useCalibrationStatus(weekId);

  if (!status) return <Skeleton />;

  const isFullyCovered = status.positions_configured === 6;
  const isPartial = status.positions_configured > 0 && status.positions_configured < 6;

  return (
    <Chip
      label={
        status.is_active
          ? `Calibration: Active (${status.positions_configured}/6 positions)`
          : 'Calibration: Not Active'
      }
      color={
        isFullyCovered ? 'success' :
        isPartial ? 'warning' :
        'default'
      }
      icon={
        isFullyCovered ? <CheckCircleIcon /> :
        isPartial ? <WarningIcon /> :
        <InfoIcon />
      }
      onClick={() => setShowAdmin(true)}
    />
  );
};
```

**Expected Impact:**
- Alert users to partial calibration (potential issue)
- Increase click-through to admin interface
- Reduce confusion about calibration status

---

### 5.3 UI Refinement Implementation Process

1. **Propose Refinement**
   - Document current UX issue
   - Gather user feedback and analytics
   - Design mockup/wireframe
   - Estimate effort and impact

2. **Validate Proposal**
   - Review with UX team
   - Get user feedback (surveys, user interviews)
   - Prioritize against other improvements

3. **Implement Refinement**
   - Create UI component updates
   - Write tests
   - Deploy to staging
   - Conduct usability testing

4. **Measure Impact**
   - Track relevant metrics (abandonment rate, completion time, etc.)
   - Compare before/after analytics
   - Gather user feedback
   - Iterate if needed

---

## 6. Issue Resolution Success Metrics

**Track monthly:**
- Average time to resolution by severity (P0: < 4 hours, P1: < 24 hours, etc.)
- User satisfaction rating (post-resolution survey)
- Issue recurrence rate (same issue reported multiple times)
- False positive rate (reported "bugs" that are working as designed)

**Target Success Criteria:**
- ✅ P0/P1 resolution within SLA 95% of the time
- ✅ User satisfaction > 85% after resolution
- ✅ Issue recurrence < 5%
- ✅ False positive < 10%

---

**Document Status:** Complete - Ready for production issue management
**Next Document:** 13.5-FUTURE-ENHANCEMENTS-ROADMAP.md
