# Performance Optimization Procedures
# Smart Score Engine Enhancement - Projection Calibration System

**Document Version:** 1.0
**Date:** 2025-11-01
**Task:** 13.3 - Performance Optimization
**Status:** Development Environment - Optimization Procedures

---

## Overview

This document defines performance optimization procedures for the Projection Calibration System. It provides systematic approaches to:

1. **Analyze slow database queries**
2. **Optimize calibration calculations**
3. **Add database indexes**
4. **Implement aggressive caching**
5. **Optimize frontend rendering**

Each procedure includes diagnostic steps, optimization techniques, and validation methods to ensure performance targets are met (< 5% import overhead per spec line 414).

---

## 1. Database Query Performance Analysis

### 1.1 Identify Slow Queries

#### Enable PostgreSQL Query Logging

**Configuration:**
```sql
-- In postgresql.conf or via ALTER SYSTEM
ALTER SYSTEM SET log_min_duration_statement = 100;  -- Log queries > 100ms
ALTER SYSTEM SET log_line_prefix = '%t [%p]: [%l-1] user=%u,db=%d,app=%a,client=%h ';
ALTER SYSTEM SET log_statement = 'none';
ALTER SYSTEM SET log_duration = 'off';
ALTER SYSTEM SET log_checkpoints = 'on';
SELECT pg_reload_conf();
```

**Monitor Slow Query Log:**
```bash
# Tail PostgreSQL log for slow queries
tail -f /var/log/postgresql/postgresql-*.log | grep "duration:"
```

#### Use pg_stat_statements Extension

**Enable Extension:**
```sql
-- One-time setup
CREATE EXTENSION IF NOT EXISTS pg_stat_statements;

-- Reset statistics
SELECT pg_stat_statements_reset();
```

**Query for Slowest Calibration-Related Queries:**
```sql
-- Find slowest queries related to calibration
SELECT
    substring(query, 1, 100) as short_query,
    calls,
    ROUND(total_exec_time::numeric, 2) as total_time_ms,
    ROUND(mean_exec_time::numeric, 2) as mean_time_ms,
    ROUND(max_exec_time::numeric, 2) as max_time_ms,
    ROUND((total_exec_time / sum(total_exec_time) OVER ()) * 100, 2) as percent_total_time
FROM pg_stat_statements
WHERE query ILIKE '%projection_calibration%'
   OR query ILIKE '%calibration_applied%'
   OR query ILIKE '%projection_%_calibrated%'
ORDER BY total_exec_time DESC
LIMIT 20;
```

**Identify Missing Indexes:**
```sql
-- Find sequential scans that might benefit from indexes
SELECT
    schemaname,
    tablename,
    seq_scan,
    seq_tup_read,
    idx_scan,
    seq_tup_read / seq_scan as avg_seq_tup_read,
    'Consider index on ' || tablename as recommendation
FROM pg_stat_user_tables
WHERE seq_scan > 100
  AND seq_tup_read / seq_scan > 1000
  AND tablename IN ('player_pools', 'projection_calibration', 'lineups', 'lineup_players')
ORDER BY seq_tup_read DESC
LIMIT 10;
```

---

### 1.2 Critical Queries to Monitor

#### Query 1: Calibration Factor Lookup During Import

**Current Query:**
```sql
SELECT
    position,
    floor_adjustment_percent,
    median_adjustment_percent,
    ceiling_adjustment_percent
FROM projection_calibration
WHERE week_id = :week_id
  AND is_active = true;
```

**Performance Target:** < 10ms
**Expected Result:** 6 rows (one per position)

**Optimization Checklist:**
- ✅ Index exists: `idx_projection_calibration_active (week_id, is_active)`
- ✅ Query uses WHERE on indexed columns
- ✅ Result set small (6 rows max)

**If Slow (> 10ms):**
1. Check index usage: `EXPLAIN ANALYZE [query]`
2. Verify index exists: `\d projection_calibration`
3. Update table statistics: `ANALYZE projection_calibration;`
4. Consider caching (see section 4.1)

---

#### Query 2: Player Pool Query with COALESCE

**Current Query:**
```sql
SELECT
    id,
    player_name,
    position,
    COALESCE(projection_floor_calibrated, projection_floor_original, floor) as floor,
    COALESCE(projection_median_calibrated, projection_median_original, projection) as projection,
    COALESCE(projection_ceiling_calibrated, projection_ceiling_original, ceiling) as ceiling,
    calibration_applied,
    smart_score
FROM player_pools
WHERE week_id = :week_id
ORDER BY smart_score DESC;
```

**Performance Target:** < 50ms for 500 players
**Expected Result:** 400-600 rows

**Optimization Checklist:**
- ✅ Index exists: `idx_player_pools_week_id (week_id)`
- ✅ Index exists: `idx_player_pools_calibration (week_id, calibration_applied)`
- ✅ ORDER BY on indexed column (smart_score)

**If Slow (> 50ms):**

**Diagnostic:**
```sql
EXPLAIN (ANALYZE, BUFFERS, FORMAT TEXT)
SELECT
    id,
    player_name,
    position,
    COALESCE(projection_floor_calibrated, projection_floor_original, floor) as floor,
    COALESCE(projection_median_calibrated, projection_median_original, projection) as projection,
    COALESCE(projection_ceiling_calibrated, projection_ceiling_original, ceiling) as ceiling,
    calibration_applied,
    smart_score
FROM player_pools
WHERE week_id = 19
ORDER BY smart_score DESC;
```

**Look for:**
- Seq Scan (bad) vs Index Scan (good)
- High "Buffers: shared read" count (disk I/O)
- Sort operation (may need index on smart_score)

**Optimizations:**

**Option 1: Add Composite Index for Sorting**
```sql
-- If ORDER BY smart_score DESC is slow
CREATE INDEX CONCURRENTLY idx_player_pools_week_smart_score
ON player_pools(week_id, smart_score DESC);
```

**Option 2: Add Partial Index for Calibrated Players**
```sql
-- If frequently querying only calibrated players
CREATE INDEX CONCURRENTLY idx_player_pools_calibrated_only
ON player_pools(week_id, smart_score DESC)
WHERE calibration_applied = true;
```

**Option 3: Optimize COALESCE (Rare)**
```sql
-- If COALESCE is expensive, materialize result
ALTER TABLE player_pools ADD COLUMN projection_floor_effective FLOAT;
ALTER TABLE player_pools ADD COLUMN projection_median_effective FLOAT;
ALTER TABLE player_pools ADD COLUMN projection_ceiling_effective FLOAT;

-- Update trigger to maintain effective values
CREATE OR REPLACE FUNCTION update_effective_projections()
RETURNS TRIGGER AS $$
BEGIN
    NEW.projection_floor_effective := COALESCE(NEW.projection_floor_calibrated, NEW.projection_floor_original, NEW.floor);
    NEW.projection_median_effective := COALESCE(NEW.projection_median_calibrated, NEW.projection_median_original, NEW.projection);
    NEW.projection_ceiling_effective := COALESCE(NEW.projection_ceiling_calibrated, NEW.projection_ceiling_original, NEW.ceiling);
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER trg_update_effective_projections
BEFORE INSERT OR UPDATE ON player_pools
FOR EACH ROW
EXECUTE FUNCTION update_effective_projections();
```

---

#### Query 3: Lineup Optimizer Player Selection

**Current Query:**
```sql
SELECT
    pp.id,
    pp.player_name,
    pp.position,
    pp.salary,
    COALESCE(pp.projection_median_calibrated, pp.projection_median_original, pp.projection) as projection,
    pp.smart_score,
    pp.ownership
FROM player_pools pp
WHERE pp.week_id = :week_id
  AND pp.smart_score >= :min_score
  AND pp.salary <= :max_salary
ORDER BY pp.smart_score DESC;
```

**Performance Target:** < 30ms for 500 players
**Expected Result:** 50-200 rows after filtering

**Optimization Checklist:**
- ✅ Index exists: `idx_player_pools_week_id (week_id)`
- ✅ Index on smart_score for filtering and sorting

**If Slow (> 30ms):**

**Add Composite Index:**
```sql
CREATE INDEX CONCURRENTLY idx_player_pools_optimizer
ON player_pools(week_id, smart_score DESC, salary)
WHERE smart_score IS NOT NULL;
```

---

#### Query 4: Calibration Status Check (Frontend)

**Current Query:**
```sql
SELECT
    COUNT(DISTINCT position) as positions_configured,
    bool_or(is_active) as is_active
FROM projection_calibration
WHERE week_id = :week_id;
```

**Performance Target:** < 5ms
**Expected Result:** 1 row

**Optimization Checklist:**
- ✅ Index exists: `idx_projection_calibration_week (week_id)`
- ✅ Small table (< 1000 rows typically)

**If Slow (> 5ms):**
- Cache result in application layer (see section 4.2)
- Result changes infrequently (only when calibration updated)

---

### 1.3 Query Optimization Process

**Step-by-Step Diagnostic:**

1. **Capture Slow Query**
   ```sql
   -- Get exact query from logs or application
   ```

2. **Analyze Query Plan**
   ```sql
   EXPLAIN (ANALYZE, BUFFERS, VERBOSE, FORMAT TEXT)
   [slow query here];
   ```

3. **Interpret Results**
   - **Seq Scan:** Table scan without index (bad for large tables)
   - **Index Scan:** Uses index (good)
   - **Index Only Scan:** Best - no table access needed
   - **Buffers: shared hit:** Data in memory (good)
   - **Buffers: shared read:** Data read from disk (slow)
   - **Planning time:** Time to plan query (< 5ms ideal)
   - **Execution time:** Time to execute query

4. **Identify Bottlenecks**
   - High execution time on specific node
   - Large number of rows scanned
   - Expensive operations (sort, hash join on large tables)

5. **Apply Optimization**
   - Add index
   - Rewrite query
   - Update statistics
   - Increase work_mem (for sorts/hashes)

6. **Validate Improvement**
   ```sql
   EXPLAIN (ANALYZE, BUFFERS) [optimized query];
   -- Compare execution time before/after
   ```

---

## 2. Calibration Calculation Optimization

### 2.1 Current Implementation Analysis

**Current Calibration Logic:**
```python
# In calibration_service.py
def calculate_calibrated_value(original: float, adjustment_percent: float) -> float:
    if original is None:
        return None
    calibrated = original * (1 + adjustment_percent / 100.0)
    return max(0, round(calibrated, 2))
```

**Performance Characteristics:**
- Time complexity: O(1) per value
- Operations: 1 multiplication, 1 addition, 1 division, 1 rounding, 1 max
- Estimated time: < 0.001ms per value
- For 500 players × 3 values = 1500 calculations ≈ 1.5ms total

**Conclusion:** Calculation is already highly optimized. Not a bottleneck.

---

### 2.2 Batch Processing Optimization

**Current Implementation:**
```python
def apply_calibration(self, players: List[dict], week_id: int, db: Session) -> List[dict]:
    calibration_map = self.get_calibration_for_week(week_id, db)

    for player in players:
        position = player['position']
        if position in calibration_map:
            # Apply calibration to each projection type
            player['projection_floor_calibrated'] = self.calculate_calibrated_value(
                player['projection_floor_original'],
                calibration_map[position]['floor_adjustment_percent']
            )
            # ... repeat for median and ceiling
```

**Optimization Opportunities:**

**Option 1: Vectorized Calculation (NumPy)**
```python
import numpy as np

def apply_calibration_vectorized(self, players: List[dict], week_id: int, db: Session) -> List[dict]:
    calibration_map = self.get_calibration_for_week(week_id, db)

    # Group players by position
    position_groups = {}
    for player in players:
        position = player['position']
        if position not in position_groups:
            position_groups[position] = []
        position_groups[position].append(player)

    # Apply calibration to each position group
    for position, group_players in position_groups.items():
        if position in calibration_map:
            factors = calibration_map[position]

            # Extract original values as numpy arrays
            floor_originals = np.array([p['projection_floor_original'] for p in group_players])
            median_originals = np.array([p['projection_median_original'] for p in group_players])
            ceiling_originals = np.array([p['projection_ceiling_original'] for p in group_players])

            # Vectorized calculation
            floor_calibrated = np.maximum(0, floor_originals * (1 + factors['floor_adjustment_percent'] / 100.0))
            median_calibrated = np.maximum(0, median_originals * (1 + factors['median_adjustment_percent'] / 100.0))
            ceiling_calibrated = np.maximum(0, ceiling_originals * (1 + factors['ceiling_adjustment_percent'] / 100.0))

            # Assign back to players
            for i, player in enumerate(group_players):
                player['projection_floor_calibrated'] = round(floor_calibrated[i], 2)
                player['projection_median_calibrated'] = round(median_calibrated[i], 2)
                player['projection_ceiling_calibrated'] = round(ceiling_calibrated[i], 2)

    return players
```

**Performance Gain:** ~30% faster for large batches (500+ players)
**Tradeoff:** Adds NumPy dependency
**Recommendation:** Only implement if import time > 5% overhead

---

**Option 2: Parallel Processing (Multiprocessing)**
```python
from multiprocessing import Pool
from functools import partial

def calibrate_player_batch(players: List[dict], calibration_map: dict) -> List[dict]:
    for player in players:
        position = player['position']
        if position in calibration_map:
            # Apply calibration...
    return players

def apply_calibration_parallel(self, players: List[dict], week_id: int, db: Session) -> List[dict]:
    calibration_map = self.get_calibration_for_week(week_id, db)

    # Split players into batches
    batch_size = 100
    batches = [players[i:i+batch_size] for i in range(0, len(players), batch_size)]

    # Process batches in parallel
    with Pool(processes=4) as pool:
        calibrate_func = partial(calibrate_player_batch, calibration_map=calibration_map)
        results = pool.map(calibrate_func, batches)

    # Flatten results
    return [player for batch in results for player in batch]
```

**Performance Gain:** ~50% faster for very large datasets (2000+ players)
**Tradeoff:** Complexity, overhead for small datasets
**Recommendation:** Only implement if processing > 1000 players per import

---

### 2.3 Memory Optimization

**Current Memory Usage:**
- Player dict: ~50 fields × 8 bytes = 400 bytes
- 500 players = 200 KB
- Calibration map: 6 positions × 3 factors = 144 bytes

**Optimization:** Already memory-efficient. No optimization needed.

---

## 3. Database Index Strategy

### 3.1 Existing Indexes (From Migrations)

**projection_calibration Table:**
```sql
-- Primary key
CREATE INDEX idx_projection_calibration_pkey ON projection_calibration(id);

-- Week lookup
CREATE INDEX idx_projection_calibration_week ON projection_calibration(week_id);

-- Active calibration lookup
CREATE INDEX idx_projection_calibration_active ON projection_calibration(week_id, is_active);

-- Unique constraint (also serves as index)
CREATE UNIQUE INDEX idx_projection_calibration_week_position ON projection_calibration(week_id, position);
```

**player_pools Table:**
```sql
-- Calibration filtering
CREATE INDEX idx_player_pools_calibration ON player_pools(week_id, calibration_applied);
```

---

### 3.2 Additional Indexes to Consider

#### Index 1: Smart Score Sorting (High Priority)

**Use Case:** Sorting players by Smart Score in player pool queries

**Analysis Query:**
```sql
-- Check if this query is slow
EXPLAIN (ANALYZE, BUFFERS)
SELECT * FROM player_pools
WHERE week_id = 19
ORDER BY smart_score DESC
LIMIT 50;
```

**If using Seq Scan + Sort:**
```sql
CREATE INDEX CONCURRENTLY idx_player_pools_week_smart_score
ON player_pools(week_id, smart_score DESC NULLS LAST);
```

**Benefit:** 50-70% faster for sorted queries
**Cost:** ~5-10 MB disk space, slight overhead on inserts
**Recommendation:** Create if ORDER BY smart_score queries > 50ms

---

#### Index 2: Position Filtering (Medium Priority)

**Use Case:** Filtering players by position for position-specific analysis

**Analysis Query:**
```sql
EXPLAIN (ANALYZE, BUFFERS)
SELECT * FROM player_pools
WHERE week_id = 19
  AND position = 'RB'
  AND calibration_applied = true;
```

**If using Seq Scan:**
```sql
CREATE INDEX CONCURRENTLY idx_player_pools_week_position
ON player_pools(week_id, position)
INCLUDE (calibration_applied);
```

**Benefit:** 40-60% faster for position-specific queries
**Cost:** ~3-5 MB disk space
**Recommendation:** Create if position filtering is common (>10 queries/day)

---

#### Index 3: Lineup Optimizer Query (Medium Priority)

**Use Case:** Lineup optimizer player selection with Smart Score filtering

**Analysis Query:**
```sql
EXPLAIN (ANALYZE, BUFFERS)
SELECT * FROM player_pools
WHERE week_id = 19
  AND smart_score >= 50
  AND salary <= 10000
ORDER BY smart_score DESC;
```

**If slow:**
```sql
CREATE INDEX CONCURRENTLY idx_player_pools_optimizer_filter
ON player_pools(week_id, smart_score DESC, salary)
WHERE smart_score IS NOT NULL;
```

**Benefit:** 60-80% faster for optimizer queries
**Cost:** ~4-6 MB disk space
**Recommendation:** Create if optimizer query > 30ms

---

#### Index 4: Calibration Update Timestamp (Low Priority)

**Use Case:** Tracking recent calibration changes

**Query:**
```sql
SELECT * FROM projection_calibration
WHERE updated_at >= NOW() - INTERVAL '7 days'
ORDER BY updated_at DESC;
```

**If slow (unlikely):**
```sql
CREATE INDEX CONCURRENTLY idx_projection_calibration_updated
ON projection_calibration(updated_at DESC);
```

**Benefit:** Faster for admin dashboards showing recent changes
**Cost:** ~1 MB disk space
**Recommendation:** Only create if admin queries > 100ms (unlikely)

---

### 3.3 Index Maintenance

**Regular Maintenance Tasks:**

**Monthly: Update Statistics**
```sql
-- Update table statistics for query planner
ANALYZE player_pools;
ANALYZE projection_calibration;
ANALYZE lineups;
ANALYZE lineup_players;
```

**Quarterly: Reindex (If Needed)**
```sql
-- Check index bloat
SELECT
    schemaname,
    tablename,
    indexname,
    pg_size_pretty(pg_relation_size(indexrelid)) as index_size,
    idx_scan,
    idx_tup_read,
    idx_tup_fetch
FROM pg_stat_user_indexes
WHERE schemaname = 'public'
  AND tablename IN ('player_pools', 'projection_calibration')
ORDER BY pg_relation_size(indexrelid) DESC;

-- Reindex if bloated or unused
REINDEX INDEX CONCURRENTLY idx_player_pools_week_smart_score;
```

**Monitor Index Usage:**
```sql
-- Find unused indexes
SELECT
    schemaname,
    tablename,
    indexname,
    idx_scan,
    pg_size_pretty(pg_relation_size(indexrelid)) as index_size,
    'Consider dropping' as recommendation
FROM pg_stat_user_indexes
WHERE schemaname = 'public'
  AND tablename IN ('player_pools', 'projection_calibration')
  AND idx_scan < 100
  AND pg_relation_size(indexrelid) > 1024 * 1024  -- > 1MB
ORDER BY pg_relation_size(indexrelid) DESC;
```

---

## 4. Aggressive Caching Strategy

### 4.1 Backend Caching - Calibration Factors

**Problem:** Calibration factors queried on every import
**Solution:** In-memory caching with TTL

**Implementation:**

**Using Python functools.lru_cache:**
```python
# In calibration_service.py
from functools import lru_cache
from datetime import datetime, timedelta

class CalibrationService:
    def __init__(self):
        self._cache_timestamp = {}
        self._cache_ttl = timedelta(minutes=15)

    def get_calibration_for_week(self, week_id: int, db: Session) -> dict:
        cache_key = f"calibration_{week_id}"

        # Check if cache is fresh
        if cache_key in self._cache_timestamp:
            if datetime.now() - self._cache_timestamp[cache_key] < self._cache_ttl:
                logger.info(f"Using cached calibration for week {week_id}")
                return self._get_calibration_cached(week_id, db)

        # Fetch fresh data
        logger.info(f"Fetching fresh calibration for week {week_id}")
        self._cache_timestamp[cache_key] = datetime.now()
        return self._get_calibration_cached(week_id, db)

    @lru_cache(maxsize=10)  # Cache last 10 weeks
    def _get_calibration_cached(self, week_id: int, db: Session) -> dict:
        # Actual database query
        calibrations = db.execute(
            text("""
                SELECT position, floor_adjustment_percent,
                       median_adjustment_percent, ceiling_adjustment_percent
                FROM projection_calibration
                WHERE week_id = :week_id AND is_active = true
            """),
            {"week_id": week_id}
        ).fetchall()

        return {
            row[0]: {
                'floor_adjustment_percent': row[1],
                'median_adjustment_percent': row[2],
                'ceiling_adjustment_percent': row[3]
            }
            for row in calibrations
        }

    def invalidate_cache(self, week_id: int):
        """Call this when calibration is updated"""
        cache_key = f"calibration_{week_id}"
        if cache_key in self._cache_timestamp:
            del self._cache_timestamp[cache_key]
        self._get_calibration_cached.cache_clear()
```

**Cache Invalidation on Update:**
```python
# In calibration_router.py
@router.post("/{week_id}")
def update_calibration(week_id: int, calibration: CalibrationCreate, db: Session = Depends(get_db)):
    # ... update database ...

    # Invalidate cache
    calibration_service.invalidate_cache(week_id)

    return {"success": True, "message": "Calibration updated and cache invalidated"}
```

**Performance Gain:** 90-95% reduction in calibration lookup time (10ms → 0.5ms)
**Tradeoff:** Stale data risk (mitigated by 15-minute TTL)
**Recommendation:** Implement immediately

---

### 4.2 Backend Caching - Calibration Status (Frontend API)

**Problem:** Frontend calls `/api/calibration/{week_id}/status` frequently
**Solution:** Server-side cache with short TTL

**Implementation using Flask-Caching (or similar):**
```python
from flask_caching import Cache

cache = Cache(config={'CACHE_TYPE': 'simple', 'CACHE_DEFAULT_TIMEOUT': 300})  # 5 minutes

@router.get("/{week_id}/status")
@cache.cached(timeout=300, query_string=True)
def get_calibration_status(week_id: int, db: Session = Depends(get_db)):
    # ... query database ...
    return {
        "week_id": week_id,
        "is_active": is_active,
        "positions_configured": positions_configured,
        "total_positions": 6
    }
```

**Alternative: Redis Caching (Production):**
```python
import redis
import json

redis_client = redis.Redis(host='localhost', port=6379, db=0)

@router.get("/{week_id}/status")
def get_calibration_status(week_id: int, db: Session = Depends(get_db)):
    cache_key = f"calibration_status_{week_id}"

    # Try cache first
    cached = redis_client.get(cache_key)
    if cached:
        logger.info(f"Cache hit for calibration status week {week_id}")
        return json.loads(cached)

    # Query database
    # ... database query ...

    result = {
        "week_id": week_id,
        "is_active": is_active,
        "positions_configured": positions_configured,
        "total_positions": 6
    }

    # Cache for 5 minutes
    redis_client.setex(cache_key, 300, json.dumps(result))

    return result
```

**Performance Gain:** 95% reduction in status API response time (20ms → 1ms)
**Recommendation:** Implement immediately for production

---

### 4.3 Frontend Caching - React Query

**Problem:** Frontend re-fetches calibration data on every navigation
**Solution:** Client-side caching with React Query

**Implementation:**

**Install React Query:**
```bash
npm install @tanstack/react-query
```

**Update useCalibration hook:**
```typescript
// In useCalibration.ts
import { useQuery, useMutation, useQueryClient } from '@tanstack/react-query';

export function useCalibrationStatus(weekId: number) {
  return useQuery({
    queryKey: ['calibration-status', weekId],
    queryFn: async () => {
      const response = await fetch(`/api/calibration/${weekId}/status`);
      if (!response.ok) throw new Error('Failed to fetch calibration status');
      return response.json();
    },
    staleTime: 5 * 60 * 1000,  // 5 minutes
    cacheTime: 10 * 60 * 1000,  // 10 minutes
    refetchOnWindowFocus: false,
    refetchOnMount: false
  });
}

export function useCalibrations(weekId: number) {
  return useQuery({
    queryKey: ['calibrations', weekId],
    queryFn: async () => {
      const response = await fetch(`/api/calibration/${weekId}`);
      if (!response.ok) throw new Error('Failed to fetch calibrations');
      return response.json();
    },
    staleTime: 10 * 60 * 1000,  // 10 minutes
    cacheTime: 30 * 60 * 1000,  // 30 minutes
  });
}

export function useUpdateCalibration() {
  const queryClient = useQueryClient();

  return useMutation({
    mutationFn: async ({ weekId, calibration }: { weekId: number, calibration: CalibrationUpdate }) => {
      const response = await fetch(`/api/calibration/${weekId}`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(calibration)
      });
      if (!response.ok) throw new Error('Failed to update calibration');
      return response.json();
    },
    onSuccess: (data, variables) => {
      // Invalidate cache on successful update
      queryClient.invalidateQueries(['calibration-status', variables.weekId]);
      queryClient.invalidateQueries(['calibrations', variables.weekId]);
    }
  });
}
```

**Performance Gain:** Eliminates redundant API calls, instant UI updates
**Recommendation:** Implement immediately (already planned in Task Group 5)

---

## 5. Frontend Rendering Optimization

### 5.1 Identify Rendering Bottlenecks

**Use React DevTools Profiler:**
1. Open React DevTools
2. Navigate to "Profiler" tab
3. Click "Record" and interact with Player Pool screen
4. Identify slow components (> 16ms render time)

**Common Bottlenecks:**
- Large table rendering (500+ rows)
- Dual-value projection display (many DOM nodes)
- Frequent re-renders due to state changes

---

### 5.2 Optimize Player Pool Table Rendering

**Problem:** Rendering 500+ player rows is slow
**Solution:** Virtual scrolling

**Implementation with react-window:**

**Install:**
```bash
npm install react-window
```

**Virtualized Table:**
```tsx
// In SmartScoreTable.tsx
import { FixedSizeList as List } from 'react-window';

interface PlayerPoolTableProps {
  players: Player[];
  weekId: number;
}

const PlayerPoolTable: React.FC<PlayerPoolTableProps> = ({ players, weekId }) => {
  const Row = ({ index, style }: { index: number, style: React.CSSProperties }) => {
    const player = players[index];
    return (
      <div style={style} className="player-row">
        <PlayerTableRow player={player} weekId={weekId} />
      </div>
    );
  };

  return (
    <List
      height={600}  // Viewport height
      itemCount={players.length}
      itemSize={50}  // Row height in pixels
      width="100%"
    >
      {Row}
    </List>
  );
};
```

**Performance Gain:** 80-90% faster rendering for 500+ rows
**Tradeoff:** Scrollbar behavior changes, accessibility considerations
**Recommendation:** Implement if table render time > 100ms

---

### 5.3 Optimize Projection Display Component

**Problem:** ProjectionDisplay component re-renders frequently
**Solution:** React.memo and useMemo

**Optimized Component:**
```tsx
// In ProjectionDisplay.tsx
import React, { useMemo } from 'react';

interface ProjectionDisplayProps {
  label: string;
  originalValue: number | null;
  calibratedValue: number | null;
  calibrationApplied: boolean;
}

export const ProjectionDisplay = React.memo<ProjectionDisplayProps>(({
  label,
  originalValue,
  calibratedValue,
  calibrationApplied
}) => {
  const displayValue = useMemo(() => {
    if (calibrationApplied && calibratedValue !== null && originalValue !== null && calibratedValue !== originalValue) {
      return (
        <>
          <span className="font-bold text-white">{calibratedValue.toFixed(1)}</span>
          {' '}
          <span className="text-gray-400 italic text-sm">(original: {originalValue.toFixed(1)})</span>
        </>
      );
    }

    const value = calibratedValue ?? originalValue;
    return value !== null ? (
      <span className="text-white">{value.toFixed(1)}</span>
    ) : (
      <span className="text-gray-500">N/A</span>
    );
  }, [calibrationApplied, calibratedValue, originalValue]);

  return (
    <div className="flex items-center gap-2">
      <span className="text-gray-400 text-sm w-16">{label}:</span>
      {displayValue}
    </div>
  );
}, (prevProps, nextProps) => {
  // Custom comparison function - only re-render if these props change
  return (
    prevProps.calibratedValue === nextProps.calibratedValue &&
    prevProps.originalValue === nextProps.originalValue &&
    prevProps.calibrationApplied === nextProps.calibrationApplied &&
    prevProps.label === nextProps.label
  );
});

ProjectionDisplay.displayName = 'ProjectionDisplay';
```

**Performance Gain:** 50-70% reduction in re-renders
**Recommendation:** Implement immediately (already done in Task Group 6)

---

### 5.4 Debounce Calibration Admin Input

**Problem:** Real-time preview re-calculates on every keystroke
**Solution:** Debounce input changes

**Implementation:**
```tsx
// In CalibrationAdmin.tsx
import { useState, useCallback } from 'react';
import { debounce } from 'lodash';

const CalibrationAdmin: React.FC = () => {
  const [floorAdjustment, setFloorAdjustment] = useState(5);
  const [previewValue, setPreviewValue] = useState(0);

  // Debounced preview calculation (500ms delay)
  const updatePreview = useCallback(
    debounce((value: number) => {
      const sampleOriginal = 12.0;
      const calibrated = sampleOriginal * (1 + value / 100);
      setPreviewValue(calibrated);
    }, 500),
    []
  );

  const handleFloorChange = (e: React.ChangeEvent<HTMLInputElement>) => {
    const value = parseFloat(e.target.value);
    setFloorAdjustment(value);
    updatePreview(value);  // Debounced
  };

  return (
    <input
      type="number"
      value={floorAdjustment}
      onChange={handleFloorChange}
      min={-50}
      max={50}
      step={0.1}
    />
  );
};
```

**Performance Gain:** Eliminates unnecessary calculations during typing
**Recommendation:** Implement if preview calculation is complex

---

### 5.5 Code Splitting and Lazy Loading

**Problem:** Large bundle size, slow initial load
**Solution:** Lazy load calibration admin modal

**Implementation:**
```tsx
// In App.tsx or PlayerPoolScreen.tsx
import React, { lazy, Suspense } from 'react';

const CalibrationAdmin = lazy(() => import('./components/calibration/CalibrationAdmin'));

const PlayerPoolScreen: React.FC = () => {
  const [showCalibrationAdmin, setShowCalibrationAdmin] = useState(false);

  return (
    <>
      <CalibrationStatusChip onClick={() => setShowCalibrationAdmin(true)} />

      {showCalibrationAdmin && (
        <Suspense fallback={<div>Loading calibration admin...</div>}>
          <CalibrationAdmin onClose={() => setShowCalibrationAdmin(false)} />
        </Suspense>
      )}
    </>
  );
};
```

**Performance Gain:** Reduces initial bundle size by 10-15%
**Recommendation:** Implement for production deployment

---

## 6. Performance Monitoring and Validation

### 6.1 Import Performance Benchmark

**Baseline Measurement (No Calibration):**
```python
# In data_importer.py
import time

def import_players_benchmark(players: List[dict], week_id: int):
    start_time = time.time()

    # Import without calibration
    # ... import logic ...

    end_time = time.time()
    baseline_time = (end_time - start_time) * 1000  # ms

    logger.info(f"Baseline import time: {baseline_time:.2f}ms for {len(players)} players")
    return baseline_time
```

**Calibration Performance Measurement:**
```python
def import_players_with_calibration(players: List[dict], week_id: int):
    start_time = time.time()

    # Import with calibration
    calibration_start = time.time()
    calibrated_players = calibration_service.apply_calibration(players, week_id, db)
    calibration_end = time.time()

    # ... rest of import ...

    end_time = time.time()

    total_time = (end_time - start_time) * 1000
    calibration_time = (calibration_end - calibration_start) * 1000
    overhead_percent = (calibration_time / total_time) * 100

    logger.info(f"Import with calibration: {total_time:.2f}ms total, {calibration_time:.2f}ms calibration ({overhead_percent:.2f}% overhead)")

    # Alert if overhead > 5%
    if overhead_percent > 5.0:
        logger.warning(f"Calibration overhead exceeds 5%: {overhead_percent:.2f}%")

    return total_time
```

**Validation:**
```python
# Run both imports and compare
baseline_time = import_players_benchmark(players, week_id)
calibrated_time = import_players_with_calibration(players, week_id)

overhead_percent = ((calibrated_time - baseline_time) / baseline_time) * 100

assert overhead_percent < 5.0, f"Performance target failed: {overhead_percent:.2f}% overhead"
```

---

### 6.2 Query Performance Tracking

**Create Monitoring Query:**
```sql
-- Create a view for slow query monitoring
CREATE OR REPLACE VIEW calibration_query_performance AS
SELECT
    substring(query, 1, 100) as query_snippet,
    calls,
    ROUND(mean_exec_time::numeric, 2) as avg_time_ms,
    ROUND(max_exec_time::numeric, 2) as max_time_ms,
    CASE
        WHEN mean_exec_time < 10 THEN 'EXCELLENT'
        WHEN mean_exec_time < 50 THEN 'GOOD'
        WHEN mean_exec_time < 100 THEN 'WARNING'
        ELSE 'CRITICAL'
    END as performance_status
FROM pg_stat_statements
WHERE query ILIKE '%projection_calibration%'
   OR query ILIKE '%calibration_applied%'
ORDER BY mean_exec_time DESC;

-- Query the view
SELECT * FROM calibration_query_performance WHERE performance_status IN ('WARNING', 'CRITICAL');
```

**Automated Alert:**
```python
# In monitoring script
def check_query_performance():
    slow_queries = db.execute("""
        SELECT * FROM calibration_query_performance
        WHERE performance_status = 'CRITICAL'
    """).fetchall()

    if slow_queries:
        alert_message = f"Found {len(slow_queries)} critical slow queries related to calibration"
        send_alert(alert_message, severity='HIGH')
```

---

### 6.3 Frontend Performance Tracking

**Using Web Vitals:**
```typescript
// In App.tsx
import { getCLS, getFID, getFCP, getLCP, getTTFB } from 'web-vitals';

function sendToAnalytics(metric: Metric) {
  const body = JSON.stringify(metric);
  const url = '/api/analytics/web-vitals';

  if (navigator.sendBeacon) {
    navigator.sendBeacon(url, body);
  } else {
    fetch(url, { method: 'POST', body, keepalive: true });
  }
}

getCLS(sendToAnalytics);
getFID(sendToAnalytics);
getFCP(sendToAnalytics);
getLCP(sendToAnalytics);
getTTFB(sendToAnalytics);
```

**Track Calibration-Specific Interactions:**
```typescript
// In CalibrationAdmin.tsx
import { useEffect, useRef } from 'react';

const CalibrationAdmin: React.FC = () => {
  const renderStart = useRef(Date.now());

  useEffect(() => {
    const renderTime = Date.now() - renderStart.current;

    if (renderTime > 100) {
      console.warn(`CalibrationAdmin slow render: ${renderTime}ms`);
      analytics.track('slow_component_render', {
        component: 'CalibrationAdmin',
        renderTime,
        threshold: 100
      });
    }
  }, []);

  // ... component code ...
};
```

---

## 7. Optimization Decision Matrix

| Optimization | Effort | Impact | Priority | Implement If |
|--------------|--------|--------|----------|--------------|
| **Database** |
| Add smart_score index | Low | High | 1 | Query > 50ms |
| Add position index | Low | Medium | 3 | Position queries common |
| Add optimizer index | Low | High | 2 | Optimizer query > 30ms |
| Update statistics | Very Low | Medium | 4 | Monthly maintenance |
| **Backend** |
| Cache calibration factors | Low | Very High | 1 | Always |
| Cache status API | Low | High | 1 | Always |
| Vectorized calculation | Medium | Low | 6 | Import > 5% overhead |
| Parallel processing | High | Medium | 7 | Processing > 1000 players |
| **Frontend** |
| React Query caching | Low | High | 1 | Always |
| Virtual scrolling | Medium | High | 2 | Table render > 100ms |
| React.memo optimization | Low | Medium | 3 | Already implemented |
| Code splitting | Low | Medium | 4 | Production deployment |
| Debounce inputs | Low | Low | 5 | Preview calculation heavy |

---

## 8. Performance Optimization Checklist

### Pre-Optimization
- [ ] Identify performance bottleneck (profiling, monitoring)
- [ ] Measure baseline performance
- [ ] Set clear performance target (e.g., < 5% overhead)
- [ ] Document current behavior

### During Optimization
- [ ] Implement optimization
- [ ] Measure performance improvement
- [ ] Verify functionality still correct
- [ ] Check for regressions in other areas
- [ ] Update tests if needed

### Post-Optimization
- [ ] Validate improvement meets target
- [ ] Document optimization approach
- [ ] Update monitoring dashboards
- [ ] Communicate changes to team
- [ ] Plan follow-up monitoring (1 week, 1 month)

---

**Document Status:** Complete - Ready for production optimization
**Next Document:** 13.4-ISSUE-TRACKING-AND-RESOLUTION.md
